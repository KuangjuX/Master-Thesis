\section{高效的内核映射策略}

\subsection{引言}

前两章分别介绍了 AffineGraph IR 的设计（第三章）和基于分块策略的硬件感知优化方法（第四章）。
AffineGraph IR 提供了一种层次化的数据流图表示，能够精确描述多内存层级的数据流动模式；分块策略和代价模型则确定了最优的分块配置和执行计划。
然而，要将这些高层次的优化决策最终转化为可在 GPU 上高效执行的代码，还需要解决一个关键问题：如何将优化后的 AffineGraph IR 系统地映射为具体的硬件指令序列。

这一从抽象表示到可执行代码的转换过程——即\textbf{内核映射}——面临多方面的挑战。
首先，数据流图中的声明式表示需要转换为命令式的嵌套循环和指令序列，同时保持数据依赖关系的正确性。
其次，不同内存层级之间的数据移动需要映射到特定的硬件指令（如 \texttt{cp.async}、\texttt{ldmatrix}），并插入适当的同步操作。
最后，数据在各内存层级中的物理布局需要经过精细的推断和变换，以满足硬件约束（如 Tensor Core 的数据布局要求、共享内存的 Bank Conflict 避免）。

本课题提出了一套完整的内核映射策略，将 AffineGraph IR 的图降低（Graph Lowering）、布局推断与变换、以及基于模板库的代码生成有机结合。
核心思想是通过对数据流图的拓扑排序遍历，递归地将每个节点转换为对应的硬件操作，同时利用仿射映射信息自动推断最优的数据布局和指令选择。

本课题在本节的组织结构如下：首先介绍代码生成和布局优化所需的预备知识；随后详细阐述图降低与代码生成算法；接着以 GEMM 为案例展示完整的编译流程；然后介绍系统的整体实现架构；最后通过在 NVIDIA A100 和 H800 上的全面实验评估，验证 AffineGraph 在多种深度学习算子上的性能表现。

\subsection{预备知识}

\subsubsection{GPU 执行模型与线程层级}

NVIDIA GPU 采用 SIMT（Single Instruction, Multiple Threads）执行模型，线程被组织为层次化的结构：

\begin{itemize}
    \item \textbf{线程（Thread）：} 最基本的执行单元，拥有私有的寄存器文件。
    \item \textbf{线程束（Warp）：} 由 32 个线程组成，是 GPU 调度和执行的基本单位。同一线程束中的线程以锁步（Lockstep）方式执行相同的指令。线程束内的线程可以通过 Warp Shuffle 指令（如 \texttt{\_\_shfl\_xor\_sync}）直接交换寄存器数据，无需经过共享内存。
    \item \textbf{线程块（Thread Block / CTA）：} 由多个线程束组成，共享同一块共享内存。线程块内的线程通过共享内存和 \texttt{\_\_syncthreads()} 屏障进行通信和同步。
    \item \textbf{网格（Grid）：} 由多个线程块组成，线程块之间通过全局内存进行通信。
\end{itemize}

在代码生成过程中，AffineGraph IR 的子图节点层级与 GPU 的线程层级之间存在自然的对应关系：最外层子图对应线程块级并行，内层子图对应线程束级并行，最内层的运算符节点对应具体的硬件指令。
这种层级对应关系是图降低算法的基础。

\subsubsection{异步数据传输与同步机制}

现代 NVIDIA GPU 提供了多种异步数据传输机制，使得数据移动可以与计算并行执行：

\begin{itemize}
    \item \textbf{\texttt{cp.async}（Ampere 架构）：} 异步拷贝指令，将数据从全局内存直接拷贝到共享内存，绕过寄存器文件。该指令由专用的异步拷贝引擎执行，不占用计算流水线。通过 \texttt{cp.async.commit\_group} 和 \texttt{cp.async.wait\_group} 指令管理异步操作的提交和等待。
    \item \textbf{\texttt{ldmatrix}：} 专用的矩阵加载指令，将共享内存中的数据按照 Tensor Core 所需的布局加载到寄存器中。一条 \texttt{ldmatrix} 指令可以一次加载 $16 \times 16$ 的矩阵片段，由一个线程束协作完成。
    \item \textbf{TMA（Tensor Memory Accelerator，Hopper 架构）：} 张量内存加速器，提供硬件加速的多维数据传输。TMA 通过描述符（Descriptor）定义传输模式，支持自动的地址计算和数据重排，进一步减少了软件开销。
\end{itemize}

代码生成器需要根据数据移动的源和目标内存层级，自动选择合适的传输指令，并在适当的位置插入同步操作以保证数据一致性。
AffineGraph IR 中仿射边的内存层级标注为这一自动选择提供了必要的信息。

\subsubsection{数据布局与 Swizzle 变换}

在 GPU 编程中，数据的物理布局对性能有着至关重要的影响。
共享内存的 Bank Conflict 问题是其中最典型的例子：NVIDIA GPU 的共享内存被划分为 32 个 Bank，每个 Bank 的宽度为 4 字节。
当同一线程束中的多个线程同时访问同一 Bank 的不同地址时，这些访问会被串行化，导致带宽下降。

Swizzle（交织）变换是解决 Bank Conflict 的标准技术。
其基本思想是对共享内存中数据的存储地址进行重新映射，使得同一线程束中的线程访问不同的 Bank。
常见的 Swizzle 模式包括：
\begin{itemize}
    \item \textbf{32 字节 Swizzle：} 对地址的低位进行异或（XOR）操作，适用于较小的 Tile 尺寸。
    \item \textbf{64 字节 Swizzle：} 对更多的地址位进行异或，适用于中等 Tile 尺寸。
    \item \textbf{128 字节 Swizzle：} 对最多的地址位进行异或，适用于较大的 Tile 尺寸，能够完全消除 Bank Conflict。
\end{itemize}

Swizzle 模式的选择需要综合考虑 Tile 尺寸、数据类型和访问模式。
AffineGraph 的布局推断过程能够根据分块配置自动选择最优的 Swizzle 策略，这是本课题布局推断与变换部分的重要内容。

\subsection{图降低与代码生成}

图降低（Graph Lowering）阶段将优化后的 AffineGraph IR 转换为可执行代码。
该过程通过对图的节点进行拓扑排序，并对排序后的每个节点递归调用代码生成函数，从而系统地将声明式的图表示转换为命令式的嵌套循环和硬件特定指令序列。

\begin{algorithm}[H]
\caption{AffineGraph 代码生成算法}
\label{alg:codegen}
\begin{algorithmic}[1]
\Procedure{Gen}{N}
    \If{\(N\) is predicated by \(P=(B_{\text{pred}}, \mathcal{A}_{\text{pred}})\)}
        \State Emit("if (\(B_{\text{pred}}[\mathcal{A}_{\text{pred}}(\vec{i})]\)) \{")
    \EndIf

    \If{\(N\) is a \textbf{SubGraph} with domain \(\mathcal{D}_N\)}
        \State Emit("for \(\vec{i} \in \mathcal{D}_N\) \{")
        \ForAll{child \(C\) in TopologicalSort(\(N\).children)}
            \Call{Gen}{$C$}
        \EndFor
        \State Emit("\}")
    \ElsIf{\(N\) is an \textbf{Operator}}
        \ForAll{edge \(E\) in \(N\).incoming\_edges}
            \State Emit(InstructionForLoad(\(E\)))
        \EndFor
        \State Emit(InstructionForSync(\(N\)))
        \State Emit(InstructionForCompute(\(N\)))
    \EndIf

    \If{\(N\) is predicated}
        \State Emit("\}")
    \EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

代码生成的核心是一个递归过程 \textsc{Gen}，如算法~\ref{alg:codegen}所示。
它根据节点类型（\(N\)）来生成相应的代码。
当遇到一个子图节点（SubGraph）时，它会生成循环头，然后递归调用自身来生成循环体。
关键逻辑在于处理算子节点（Operator）。
算法首先为其所有传入的数据依赖（边）生成相应的数据加载指令（例如，针对不同内存层级的 \textit{cp.async} 或 \textit{ld.matrix} 指令）。
在所有加载指令发出后，它会生成一个同步指令（如 \textit{barrier}）来等待异步操作完成，最后才生成算子的计算指令。
这种形式化的递归定义，使得从层级化的图表示到结构化的高性能代码的转换过程清晰而系统。

\subsection{案例研究：以 GEMM 为例}

为了更具体地说明 AffineGraph 的工作流程，本节以矩阵乘法（GEMM）为例，展示如何将一个复杂的计算内核通过 AffineGraph 的层级化表示、变换和代码生成流程，最终映射为高性能的 CUDA 代码。


\begin{figure*}%[h]
  \centering
  \includegraphics[width=0.95\linewidth, trim=0 0 0 0, clip]{figures/innovation3/gemm_case_v5.pdf}
  \caption{使用 AffineGraph 的 GEMM 案例研究。
  (a) Python DSL 中的 AffineGraph IR，展示了跨越内存层级（全局、共享、寄存器）的缓冲区声明、用于 K 维分块的循环变量，以及定义数据移动模式的仿射映射。
  (b) 降低后的数据流图，具有显式的依赖关系，且每条数据传输边都标注了仿射变换矩阵。
  (c) 展示矩阵 A 数据流的 GPU 架构映射：全局内存中的 K 循环迭代 CTA 级分块；共享内存中带有 Swizzle$\langle$2,3,3$\rangle$ 的 4-warp (2$\times$2) 协作；寄存器中分解为 4$\times$2 ldmatrix 分块的 WarpTile (64$\times$32)；以及 Tensor Core MMA 执行流水线。
  }
  \label{figure:gemm_case}
\end{figure*}

\paragraph{层级化 IR 构建与数据流表示}
如图~\ref{figure:gemm_case}(a) 所示，GEMM 的 AffineGraph IR 描述首先在不同的内存空间（全局内存 gA、共享内存 sA、寄存器 acc）中声明缓冲区。
接着，通过一系列仿射映射（AffineMap）来精确定义数据分块和移动的逻辑。
例如，\textit{Map\_G2S\_A} 定义了如何将一个 128x32 的数据块从全局内存移动到共享内存。
这些仿射映射被组织在嵌套的块（Block）和图（Graph）中，直接反映了分块 GEMM 算法的嵌套循环结构。


随后，这个高层 IR 被降低为一个显式表达所有依赖关系的数据流图，如图~\ref{figure:gemm_case}(b) 所示。
在这个图中，代表数据传输的边（例如从 gA 到 sA）会被相应的仿射映射所标注，使得精确的分块和访问模式成为图的一部分，为后续的自动化分析和变换提供了基础。

图~\ref{figure:gemm_case}(c) 则更详细地展示了矩阵 A 的数据如何被分块并映射到 GPU 的执行和内存层级。
全局矩阵首先被划分为线程块（CTA）级别的大块，并通过 slice-k 方法分步加载到共享内存。
在 CTA 内部，线程束（Warp）协作从共享内存中加载更小的微块到寄存器，以执行 MMA 指令。
AffineGraph 为这整个分块和线程映射的层级结构提供了统一的数学表示。

代码~\ref{lst:gemm_dsl_example} 展示了使用 AffineGraph IR 定义 GEMM 算子的代码示例。
在代码中，首先定义了全局内存、共享内存和寄存器内存的缓冲区（Buffer），接着定义了计算算子（Operator）。
通过构建分层的子图（SubGraph）结构，将算子与特定循环层级关联，并使用仿射映射（AffineMap）显式地描述了数据在不同内存层级间的流动与依赖关系。最终调用 \texttt{codegen()} 接口即可生成对应的硬件代码。

\begin{figure}[h]
\begin{lstlisting}[language=AffineDSL, caption={使用 AffineGraph IR 实现的 GEMM 示例}, label={lst:gemm_dsl_example}]
# Define Buffer node
gA  = Buffer("gA",  [256, 256], space="global")
sA  = Buffer("sA",  [64, 64],   space="shared")
rA  = Buffer("rA",  [16, 16],   space="register")
acc = Buffer("acc", [16, 16],   space="register")

# Define Operator node
reg_mma = Operator("mma.sync", inputs=[rA, ...], output=acc)

# Building a hierarchical SubGraph structure
s2r_subgraph = SubGraph(
    loop="k_inner",
    nodes=[reg_mma],
    affine_map=AffineMap(sA, rA, loop="k_inner")
)

top_level_graph = SubGraph(
    loop="k_outer",
   nodes=[s2r_subgraph],
   affine_maps=[
        AffineMap(gA, sA, loop="k_outer"), # Load: gA -> sA
        AffineMap(gB, sB, ...),         # (Load gB -> sB)
        AffineMap(acc, gC, ...)         # (Store final result)
    ]
)
final_code = top_level_graph.codegen()
\end{lstlisting}
\end{figure}

\begin{figure*}[h]
  \centering
  \includegraphics[width=\linewidth, trim=0 0 0 0, clip]{figures/innovation3/layout_transformation.pdf}
  \caption{AffineGraph 中的布局推断与变换流水线。
  (a) 从全局到共享内存的数据加载，根据 WarpLayout 自动进行向量化和合并内存访问。
  (b) 共享内存布局推断，展示了如何根据 SharedTile 和 WarpLayout 推导 WarpTile 配置，并采用自适应的 Swizzling 策略来平衡 Bank Conflicts 和 CTA 占用率。
  (c) 寄存器级的 BaseTile 抽象，其中单个线程处理8个元素，32个线程协作处理 16x16 的 ld.matrix 块以实现高效的 mma.sync 操作。
  }
  \label{figure:layout_inference}
\end{figure*}

\paragraph{布局推断与变换}
在层级化 IR 构建之后，编译器会执行一个复杂的\textbf{布局推断}过程，将逻辑表示转换为具体的、经过硬件优化的执行计划，如图~\ref{figure:layout_inference} 所示。
这个过程分为三个关键阶段：
\begin{enumerate}
    \item \textbf{从全局到共享内存的加载与自动向量化：} 编译器根据给定的 WarpLayout 配置，自动推断出线程束应如何迭代访问 GlobalTile 以最高效地加载数据，并自动应用向量化和合并访问优化，以最大化内存带宽利用率。
    \item \textbf{共享内存布局推断与自适应 Swizzling：} 编译器根据 SharedTile 和 WarpLayout 的信息，自动推导最优的 WarpTile 配置。一个关键创新是自适应的 Swizzling 策略，它会根据 WarpTile 的维度自动选择合适的 Swizzling 模式（例如 32字节、64字节或128字节），在内存访问效率和 CTA 占用率之间进行权衡。
    \item \textbf{寄存器级 BaseTile 抽象与张量核心集成：} 在最后阶段，数据被组织以用于寄存器级的计算。AffineGraph 引入了 BaseTile 抽象，定义了单个线程处理的最小单元。32个线程协作形成一个 WarpTile，其大小恰好匹配 16x16 的 \textit{ld.matrix} 操作，从而高效地将矩阵片段加载到为张量核心（Tensor Core）优化的寄存器中，为后续的 \textit{mma.sync} 计算做好准备。
\end{enumerate}

\paragraph{从数据流图生成 CUDA 代码}
最后，AffineGraph 将优化后的数据流图转换为高性能的 CUDA 代码。
这一过程由一个基于 C++ 模板库的后端实现。
代码生成器遍历数据流图，并根据在优化阶段确定的分块形状、布局和数据类型来实例化相应的模板组件（如 \textit{GlobalToSharedLoader}, \textit{SharedToRegLoader}）。
最终生成的内核代码结构清晰，通过一个 \textit{traits} 结构体来集中管理所有编译时配置，其主循环体则精确地协调了数据在不同内存层级间的流水线移动和计算。

\begin{figure}
\begin{lstlisting}[language=cplus, caption={基于模版库生成的 CUDA kernel}, label={lst:gemm_codegen}]
// 1. Traits struct centralizes kernel configuration.
struct KeGemmTraits {
  // ... tile dimensions, data layouts, and types for A, B, C ...
  using G2SLoaderA = GlobalToSharedLoader<...>;
  using S2RLoaderA = SharedToRegLoader<...>;
};
// 2. Kernel implementation uses types from Traits.
template <typename Traits>
__global__ void gemm(const InType* dA, const InType* dB, AccType* dC) {
  // ... setup memory pointers and tile offsets ...
  typename Traits::G2SLoaderA g2s_a;
  typename Traits::S2RLoaderA s2r_a;
  typename Traits::RegC acc; // Accumulators in registers
  // 3. Main loop for pipelined data movement and computation.
  for (int k = ...) {
    // Load tiles from global to shared memory
    g2s_a(gAs(k), sA);
    g2s_b(gBs(k), sB);
    __copy_async();
    __syncthreads(); // Wait for loads
    // Inner loop for computation
    for (int k_inner = ...) {
      s2r_a(sAs(k_inner), rA); // Load from shared to registers
      s2r_b(sBs(k_inner), rB);
      compute::gemm(rA, rB, acc);
    }
  }
  // 4. Store results back to global memory.
  r2s_c(acc, sC);
  __syncthreads();
  s2g_c(sC, gC);
}
\end{lstlisting}
\end{figure}

\subsection{系统实现}

AffineGraph 的实现采用了 Python、Rust 和 C++ 混合编程。编程接口和解析器由约 700 行 Python 代码实现，提供了友好的 API 用于定义计算图和应用优化。

图表示和优化组件包含约 4,000 行 Rust 代码，用于分析和变换 AffineGraph IR。该组件处理图遍历、依赖分析以及将高级 IR 转换为特定硬件表示的图降级算法。Rust 核心利用 Rust 的所有权模型在保持高性能的同时确保内存安全。

最后，特定硬件的代码生成组件由约 15,000 行 C++ 代码实现（TileFusion）。该组件为 NVIDIA GPU 生成高度优化的 CUDA 代码，高效利用 Tensor Core 进行矩阵乘法运算，并优化跨不同存储层次的数据移动。C++ 后端是一组专用的代码生成器，支持 AffineGraph IR 在 NVIDIA Ampere GPU 上的高效执行。

\paragraph{Hopper 架构原型。}
为了验证 AffineGraph 设计原则在 Ampere 架构之外的可移植性，我们针对内存受限操作实现了一个面向 NVIDIA Hopper (H800) 的原型。该原型遵循 AffineGraph 的核心方法论——具有显式存储层次映射的分层切片——并使用 NVIDIA 的 CuTe DSL~\cite{CUTLASS} 实现，该 DSL 为 Hopper 特有的功能（如 TMA 和线程块集群）提供了 Python 级别的抽象。特别是，该原型采用了 \S\ref{sec:hopper-extension} 中描述的相同的基于切片的数据流设计：数据移动被组织为一个分层的 Global$\rightarrow$Shared$\rightarrow$Register 流水线，并针对大切片尺寸采用集群级协作加载。该原型表明，AffineGraph 的设计可以自然地扩展到 Hopper 增强的存储子系统，只需要在后端指令选择层面进行更改，而保留相同的 IR 级抽象。将 Hopper 代码生成后端完全集成到编译器中是一项工程工作，不需要对 IR 或优化流水线进行根本性的更改。

\subsection{实验评估}

\paragraph{实验环境设置} 本课题的实验是在配备 80GB HBM2 显存的 NVIDIA A100 GPU 上进行的，该 GPU 拥有 108 个流多处理器（SM），其峰值 FP16 Tensor Core 性能达到 312 TFLOPS。

\paragraph{深度学习负载} 本课题的评估侧重于构成大语言模型基础的基本深度学习操作。
本课题首先从表现出各种访问模式的原始内存操作（Load/Store）开始，这对于理解本课题编译器的基本内存访问能力至关重要。
对于矩阵操作，本课题评估了具有不同维度（M, N, K）的标准矩阵乘法（GEMM），以评估编译器优化计算密集型操作的能力。
为了展示算子融合的有效性，本课题测试了融合的两个 GEMM 操作，其中两个连续的矩阵乘法被组合成一个单一操作。
本课题还评估了 Batched GEMM 操作，这对于经常同时处理多个输入的深度学习负载至关重要。
最后，本课题评估了编译器在 FlashAttention~\cite{dao2022flashattention}（一种内存高效的注意力机制）上的性能，涵盖了不同的序列长度和隐藏层大小。
选择这些负载是为了全面评估本课题的编译器在处理内存受限（Memory-bound）和计算受限（Compute-bound）操作方面的能力，以及其在优化复杂算法模式方面的有效性。

\paragraph{性能评估方法论}
本课题的性能评估遵循数据移动驱动的分析范式。
Huang 等人~\cite{huang2024orojenesis} 在 ISCA 2024 上提出的 Orojenesis 方法指出，对于张量算法而言，实际可达的数据移动量可能比传统的算法最小值（Algorithmic Minimum）高出数个数量级，尤其是在内存层级的内层。
这意味着，仅通过峰值 FLOPS 和理论带宽来评估编译器的性能是不充分的——还需要考察编译器在给定片上存储容量下，能够多大程度地逼近数据移动的理论下界。
因此，本课题在评估中不仅报告了执行时间和吞吐量等传统指标，还通过有效内存带宽（Effective Bandwidth）和带宽利用率（Bandwidth Utilization）等指标来衡量 AffineGraph 在数据移动优化方面的效率。
特别是对于融合操作（如融合双 GEMM 和 FlashAttention），Orojenesis 的理论分析表明，通过利用生产者-消费者之间的 Tile 级数据复用可以显著缩减数据移动量，这与 AffineGraph 通过仿射分析自动识别跨算子数据复用机会的设计理念高度一致。

\paragraph{基准对比} 本课题将 AffineGraph 与最先进的 DNN 框架和库进行了比较。
对于标准矩阵乘法（GEMM），本课题与 NVIDIA 针对 CUDA 优化的 BLAS 库 cuBLAS、提供线性代数子程序 CUDA 模板的 CUTLASS~\cite{CUTLASS} 以及用于编写高效 GPU 代码的开源语言和编译器 Triton~\cite{pldi/tillet2019triton} 进行了评估。
对于融合 GEMM 操作，本课题将 CUTLASS、PyTorch~\cite{nips/paszke2019pytorch} 和 Triton~\cite{pldi/tillet2019triton} 作为基准。
对于注意力操作，本课题与 FlashAttention 算法的手动优化实现 FlashAttention-2~\cite{dao2023flashattention}、PyTorch 和 Triton 进行了比较。
所有评估均以预热迭代开始，随后重复执行每个负载至少 5 秒，以确保结果准确稳定。
平均性能指标（如加速比）是使用所有实验的几何平均值计算得出的。

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/evaluations/layout_comparison.pdf}
    \caption{不同形状和不同 Warp Layout 下的内存操作（Load/Store）性能对比。柱状图上方的数字表示加速比（CUTLASS/AffineGraph）。AffineGraph 在较大矩阵上取得了最高 1.50 倍的加速。}
    \label{figure:layout_comparison}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/evaluations/affine_evaluation.pdf}
    \caption{AffineGraph 与基准框架的性能对比。
    (a) 不同矩阵规模下的标准 GEMM；
    (b) 不同批量大小下的 Batched GEMM；
    (c) 融合双 GEMM 操作；
    (d) 隐藏维度为 128 的 FlashAttention；
    (e) 隐藏维度为 256 的 FlashAttention；
    (f) 隐藏维度为 64 的 Block Sparse Attention；
    (g) 隐藏维度为 128 的 Block Sparse Attention。
    纵轴为执行时间（ms），越低越好。}
    \label{figure:affine_evaluation}
\end{figure}

\subsubsection{NVIDIA A100 上的算子性能}

图~\ref{figure:affine_evaluation} 展示了所有算子配置的性能结果。横轴表示不同的算子配置，纵轴表示以毫秒为单位的执行时间。

\paragraph{内存操作}
本课题首先在原始的 Load/Store 操作上评估 AffineGraph，以评估其基本的内存访问优化能力。
如图~\ref{figure:layout_comparison} 所示，在从 $16 \times 64$ 到 $128 \times 256$ 的矩阵形状上进行了性能测试。
AffineGraph 在小矩阵（$16 \times 64$ 和 $64 \times 64$）上的性能与 CUTLASS 相差不超过 1.3\%。
随着矩阵尺寸的增大，性能优势愈发明显：在 $128 \times 128$ 时取得了 11.2\% 的加速，在 $128 \times 256$ 时更是达到了 33.3\% 的加速。
这一提升源于 AffineGraph 利用基于仿射的分析来建模复杂的内存访问模式，并生成高效的内存层级遍历代码的能力。
性能提升在较大矩阵上尤为显著，因为此时内存访问模式更加复杂，优化空间也更为充裕。

\paragraph{GEMM}
如图~\ref{figure:affine_evaluation}(a) 所示，标准 GEMM 操作在从 $1024^3$ 到 $8192^3$ 的矩阵规模上进行了性能测试。
尽管现有编译器和库已经提供了高度优化的 GEMM 内核，AffineGraph 仍然取得了具有竞争力的性能。
与 CUTLASS 相比，AffineGraph 平均达到了 0.92 倍的性能（最高 1.08 倍）。
与 Triton 相比，AffineGraph 保持了一致的优势，平均加速比为 1.14 倍（最高 1.36 倍）。
虽然 AffineGraph 并未在所有配置上超越经过多年手动优化和架构特定调优的 cuBLAS 等厂商库，但取得接近手写优化实现的性能表明，本课题的编译器生成代码已经能够逼近手动优化的水平。
值得注意的是，AffineGraph 在不使用手动调优或流水线优化的情况下实现了这一性能，完全依赖于 AffineGraph IR 通过仿射分析建模内存层级转换和计算模式的能力。

对于批量矩阵乘法（Batch GEMM）操作（图~\ref{figure:affine_evaluation}(b)），本课题评估了批量大小从 2 到 16 的配置。
AffineGraph 在不同批量大小下展现了稳定的性能，执行时间在 CUTLASS 的 0.87--0.97 倍范围内。
随着批量大小增加，性能保持稳定，这突显了本课题框架通过有效的内存访问建模来高效处理批量操作的能力。

\paragraph{融合双 GEMM}
与标准 GEMM 操作相比，融合双 GEMM 涉及更复杂的计算阶段和数据依赖关系，为 AffineGraph 开辟了更大的优化空间。
如图~\ref{figure:affine_evaluation}(c) 所示，融合双 GEMM 操作在从 $1024 \times 1024$ 到 $8192 \times 8192$ 的矩阵规模上进行了测试（K 和 P 维度固定为 128）。
AffineGraph 在所有矩阵规模上都展现了显著的性能优势。
与 CUTLASS、Triton 和 cuBLAS 相比，AffineGraph 分别取得了平均 2.52 倍（最高 3.02 倍）、2.18 倍（最高 3.26 倍）和 1.94 倍（最高 2.41 倍）的加速。
这与标准 GEMM 中 AffineGraph 仅具有竞争力但并非始终更快的情况形成了鲜明对比。

这一提升源于 AffineGraph 利用基于仿射的分析自动识别跨融合操作的数据重用机会的能力。
对于 $D = (A \times B) \times C$ 的计算模式，当维度允许时，本课题的编译器将中间结果 $A \times B$ 保留在共享内存中，从而消除了一次到全局内存的往返传输。
基准方案要么执行独立的内核（cuBLAS、PyTorch），产生全局内存的写入/读取开销，要么需要手动指定融合方式（Triton、CUTLASS）。
AffineGraph 的仿射分析能够自动判断何时融合是有益的，并生成优化的融合内核。
当中间维度（K、P）较小（本实验中为 128）时，中间结果可以完全放入共享内存，此时效果尤为显著。
持续的 2--3 倍加速验证了 AffineGraph 的一个核心能力：高层次的仿射建模能够实现自动的跨算子优化，而这种优化通过手动编程或传统编译器方法很难实现。

\paragraph{FlashAttention}
与 GEMM 和融合 GEMM 操作相比，FlashAttention 涉及更深层次的计算阶段和更复杂的内存访问模式，为 AffineGraph 提供了更大的优化空间。
如图~\ref{figure:affine_evaluation}(d-e) 所示，FlashAttention 算子在隐藏维度为 128 和 256 的配置下进行了评测。
评估覆盖了从 128 到 4096 的序列长度，批量大小为 32，注意力头数为 8。

AffineGraph 在较短序列长度下展现了尤为突出的性能。
对于隐藏维度 128（图~\ref{figure:affine_evaluation}(d)），AffineGraph 相比 FlashAttention-2 分别取得了 3.72 倍（seqlen=128）、1.69 倍（seqlen=256）和 1.05 倍（seqlen=512）的平均加速。
随着序列长度的增加，AffineGraph 保持了具有竞争力的性能，在较长序列下执行时间与 FlashAttention-2 接近。
与 Triton 相比，AffineGraph 取得了平均 1.24 倍（最高 3.72 倍）的加速。
对于隐藏维度 256（图~\ref{figure:affine_evaluation}(e)），AffineGraph 展现了类似的趋势，相比 FlashAttention-2 分别取得了 1.61 倍（seqlen=128）、1.16 倍（seqlen=256）和 1.08 倍（seqlen=512）的平均加速，并且相比 Triton 保持了最高 3.06 倍的一致优势。

与序列长度相关的性能表现揭示了 AffineGraph 优化策略的特点。
在较短序列下，编译器在分块大小选择上具有更大的灵活性，能够更好地利用共享内存中的数据重用。
随着序列长度的增加，工作集增大，缓存效率降低，FlashAttention-2 手动调优的分块策略变得更为有效，差距逐渐缩小。
这种通用的调度能力使 AffineGraph 能够达到与手动优化实现相当的性能，在某些配置下甚至超越它们。
这突显了 AffineGraph 通过仿射分析定义的优化空间自动发现有效优化方案的能力。

\paragraph{Block Sparse Attention}
如图~\ref{figure:affine_evaluation}(f-g) 所示，Block Sparse Attention 操作在隐藏维度为 64 和 128 的配置下进行了评测，序列长度范围为 128 到 1024。
Block Sparse Attention 引入了不规则的内存访问模式和条件计算，为编译器优化提供了具有挑战性的测试。

对于隐藏维度 64（图~\ref{figure:affine_evaluation}(f)），AffineGraph 与 Triton 取得了具有竞争力的性能，在不同序列长度下性能比为 0.82 倍到 1.00 倍。
与 FlashAttention-2 相比，AffineGraph 展现了显著的优势，平均加速比为 2.5--9.4 倍。
与 FlashAttention-2 之间的巨大差距反映了 FlashAttention-2 针对密集注意力进行了优化，在适配稀疏模式时会产生额外开销。
与 PyTorch 相比，AffineGraph 保持了 15.6--19.0 倍的显著加速。

对于隐藏维度 128（图~\ref{figure:affine_evaluation}(g)），AffineGraph 继续展现了强劲的性能。
与 Triton 相比，AffineGraph 取得了 0.91 倍到 1.07 倍的加速。
与 FlashAttention-2 和 PyTorch 相比，AffineGraph 分别取得了平均 1.7--6.2 倍和 11.9--14.2 倍的加速。

这些结果突显了 AffineGraph 在处理新兴稀疏注意力模式方面的适应性。
稀疏块结构引入了条件计算和非连续内存访问，这对传统编译器构成了挑战。
AffineGraph 基于仿射的分析成功捕捉了这些不规则模式并生成了高效代码，展示了本课题方法在规则密集计算之外的通用性。
这一能力对于大规模模型尤为重要，因为稀疏注意力模式正越来越多地被用于在保持模型质量的同时降低计算成本。

\subsubsection{小结}

综合以上实验结果，AffineGraph 在多种典型深度学习算子上都取得了具有竞争力的性能。
在标准 GEMM 和 Batch GEMM 上，AffineGraph 的性能与 CUTLASS 相当并显著优于 Triton；
在融合 GEMM 操作上展示了 2--3 倍的显著加速优势；
在 FlashAttention 上，尤其在短序列场景下取得了最高 3.72 倍的性能提升；
在 Block Sparse Attention 上，展现了处理不规则计算模式的通用能力。
这些结果验证了 AffineGraph 作为一个新型编译器框架在生成高性能硬件代码方面的有效性，尤其是在处理复杂的、需要硬件感知的算法时，其优势更为明显。

\subsubsection{面向 Hopper 架构的可移植性评估}\label{sec:hopper-eval}

为了评估 AffineGraph 设计在 Ampere 架构之外的通用性，本课题在 NVIDIA H800 GPU（Hopper 架构）上进行了额外的实验。
H800 配备 80GB HBM3 显存，峰值内存带宽为 3.35 TB/s。
本课题聚焦于内存受限（Memory-bound）操作——Softmax 和 RMSNorm，这类操作对内存子系统压力较大，能够充分受益于 Hopper 架构的增强特性。

\paragraph{实验设置}
本课题按照 AffineGraph 的层级化分块方法论（第~\ref{sec:hopper-extension}~节），实现了 Softmax 和 RMSNorm 内核，利用了 Hopper 特有的功能，包括线程块集群（Thread Block Clusters）用于协作数据加载，以及 Warpgroup 级别的归约操作。
基准对比方案包括 \texttt{torch.compile}（PyTorch 2.x 的编译器）和 Liger Kernel（一个基于 Triton 的、针对 LLM 训练优化的内核库）。
所有输入使用 FP16 精度。
输入形状范围为 $[M, N] = [32768, 1024]$ 到 $[4096, 131072]$，覆盖了从高窄矩阵到矮宽矩阵的广泛内存访问模式。

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/evaluations/hopper_membound_evaluation.pdf}
    \caption{NVIDIA H800（Hopper）上内存受限操作的性能。
    (a) Softmax 延迟。(b) Softmax 有效带宽。
    (c) RMSNorm 延迟。(d) RMSNorm 有效带宽。
    AffineGraph 在所有配置下均维持约 2900 GB/s 的有效带宽，接近 H800 的 3350 GB/s 峰值 HBM3 带宽。N/A 表示该框架不支持给定的配置。}
    \label{figure:hopper_evaluation}
\end{figure}

\paragraph{实验结果}
图~\ref{figure:hopper_evaluation} 展示了实验结果。

对于 Softmax（图~\ref{figure:hopper_evaluation}(a-b)），AffineGraph 在所有配置下相比 \texttt{torch.compile} 取得了 1.2--2.2 倍的加速。
与 Liger Kernel 相比，AffineGraph 在中等规模（$N \leq 32$K）下保持了相当的性能，在 $N = 64$K 时取得了 1.6 倍的加速，并且能够扩展到 $N = 128$K，而 Liger Kernel 由于 Triton 的分块大小限制在此规模下无法运行。
AffineGraph 在所有形状下维持了 2765--2996 GB/s 的有效内存带宽，达到了 H800 峰值 HBM3 带宽的 89\%。

对于 RMSNorm（图~\ref{figure:hopper_evaluation}(c-d)），AffineGraph 相比 \texttt{torch.compile} 取得了 1.2--1.7 倍的加速。
与 Liger Kernel 相比，AffineGraph 在中小规模下展现了相当的性能，但在 $N = 64$K 时取得了 3.2 倍的加速（此时 Liger Kernel 的 Triton 后端效率显著下降），并且能够扩展到 Liger Kernel 不支持的 $N = 128$K。
AffineGraph 全程维持了 2743--2969 GB/s 的有效带宽。

\paragraph{分析}
从 Hopper 实验结果中可以得出两个关键观察：

\textbf{（1）持续接近峰值的带宽利用率。}
AffineGraph 在 Softmax 和 RMSNorm 的所有配置下均维持了约 2900 GB/s（约 87\%）的 H800 峰值带宽。
这证实了 AffineGraph 的层级化分块方法论——将数据在全局内存$\rightarrow$共享内存$\rightarrow$寄存器之间进行分区，并采用集群级别的协作加载——能够有效利用 Hopper 增强的内存子系统。

\textbf{（2）对大分块尺寸的可扩展性。}
AffineGraph 设计的一个关键优势在于其支持大的每行维度（$N$ 最高达 131K），这得益于集群级别的协作和多阶段分块。
\texttt{torch.compile} 和 Liger Kernel（基于 Triton）在 $N \geq 64$K 时要么性能显著下降，要么完全失败，因为 Triton 的分块大小受限于其编译器的最大分块维度。
AffineGraph 显式的内存层级建模使得灵活的分块策略成为可能，能够将大维度在集群内的多个加载阶段中进行分区，从而避免了这一限制。

这些结果验证了 AffineGraph 的核心抽象——层级化内存建模和基于仿射的访问模式分析——在不同 GPU 代际之间具有可移植性。
Hopper 原型仅需要指令级别的适配（TMA 替代 \texttt{cp.async}，Warpgroup 替代 Warp 级别的 MMA），同时保持了相同的高层设计，证实了第~\ref{sec:hopper-extension}~节中讨论的架构可扩展性。
