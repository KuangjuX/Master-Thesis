\relax 
\bibstyle{setup/bib-styles/gbt7714-numerical}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{lecun1998cnn}
\citation{rumelhart1986rnn}
\citation{hochreiter1997lstm}
\citation{goodfellow2020gan}
\citation{osdi/abadi2016tensorflow}
\citation{nips/paszke2019pytorch}
\citation{arxiv/chen2015mxnet}
\citation{tvm/chen2018tvm}
\citation{xla}
\citation{dao2022flashattention,dao2023flashattention,arxiv/graef2024flash}
\citation{arxiv/yang2023gated}
\citation{pldi/tillet2019triton}
\@writefile{toc}{\contentsline {section}{\numberline {一}绪论}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}研究背景及意义}{1}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 本研究系统总体路线}}{2}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{figure:abstract}{{1}{2}{本研究系统总体路线}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}研究内容及主要工作}{2}{subsection.1.2}\protected@file@percent }
\citation{lecun1998cnn}
\citation{rumelhart1986rnn}
\citation{hochreiter1997lstm}
\citation{goodfellow2020gan}
\citation{nips/vaswani2017attention}
\citation{dao2023flashattention}
\citation{arxiv/fu2023flashfftconv}
\citation{arxiv/graef2024flash}
\citation{osdi/zhu2022roller}
\citation{osdi/shi2023welder}
\citation{sosp/zheng2023pit}
\citation{tvm/chen2018tvm}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}基于多内存层级数据流图的抽象}{3}{subsubsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}基于分块策略的内核融合策略}{3}{subsubsection.1.2.2}\protected@file@percent }
\citation{chetlur2014cudnn}
\citation{CUTLASS}
\citation{arxiv/spector2024thunderkittens}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}高效的内核映射策略}{4}{subsubsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}本文组织结构}{4}{subsection.1.3}\protected@file@percent }
\citation{tvm/chen2018tvm}
\citation{xla}
\citation{cgo/baghdadi2019tiramisu}
\citation{pldi/tillet2019triton}
\citation{cute}
\citation{arxiv/spector2024thunderkittens}
\citation{arxiv/wang2025tilelang}
\citation{tvm/chen2018tvm}
\citation{tvm/chen2018tvm}
\citation{tvm/chen2018tvm}
\citation{xla}
\citation{nips/paszke2019pytorch}
\citation{tvm/chen2018tvm}
\citation{tvm/lai2023relax,tvm/roesch2018relay}
\citation{tvm/zheng2020ansor}
\citation{tvm/zheng2020ansor}
\citation{nips/chen2018learning}
\citation{tvm/zheng2020ansor}
\citation{tvm/xing2022bolt}
\citation{tvm/xing2022bolt}
\citation{CUTLASS}
\@writefile{toc}{\contentsline {section}{\numberline {二}相关技术概述}{6}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}基于 DAG 的深度学习编译器}{6}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces TVM 深度学习编译器架构\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces \cite  {tvm/chen2018tvm}}}{7}{figure.caption.5}\protected@file@percent }
\newlabel{figure:tvm}{{2}{7}{TVM 深度学习编译器架构~\cite {tvm/chen2018tvm}}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Ansor 系统设计\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces \cite  {tvm/zheng2020ansor}}}{7}{figure.caption.6}\protected@file@percent }
\newlabel{figure:Ansor}{{3}{7}{Ansor 系统设计~\cite {tvm/zheng2020ansor}}{figure.caption.6}{}}
\citation{isca/zheng2022amos}
\citation{isca/zheng2022amos}
\citation{isca/zheng2022amos}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces BOLT 系统设计\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces \cite  {tvm/xing2022bolt}}}{8}{figure.caption.7}\protected@file@percent }
\newlabel{figure:BOLT}{{4}{8}{BOLT 系统设计~\cite {tvm/xing2022bolt}}{figure.caption.7}{}}
\citation{cgo/baghdadi2019tiramisu}
\citation{cgo/baghdadi2019tiramisu}
\citation{TPDS/li2020deep}
\citation{wolf1991data}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces AMOS 系统设计\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces \cite  {isca/zheng2022amos}}}{9}{figure.caption.8}\protected@file@percent }
\newlabel{figure:AMOS}{{5}{9}{AMOS 系统设计~\cite {isca/zheng2022amos}}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}基于多面体模型的深度学习编译器}{9}{subsection.2.2}\protected@file@percent }
\citation{cgo/baghdadi2019tiramisu}
\citation{pldi/zhao2021akg}
\citation{pldi/tang2022freetensor}
\citation{verdoolaege2010isl}
\citation{Blaschek1994}
\citation{pip}
\citation{loechner1999polylib}
\citation{cgo/baghdadi2019tiramisu}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Tiramisu 系统设计\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces \cite  {cgo/baghdadi2019tiramisu}}}{10}{figure.caption.9}\protected@file@percent }
\newlabel{figure:Tiramisu}{{6}{10}{Tiramisu 系统设计~\cite {cgo/baghdadi2019tiramisu}}{figure.caption.9}{}}
\citation{pldi/tillet2019triton}
\citation{pldi/tillet2019triton}
\citation{pldi/tillet2019triton}
\citation{cgo/lattner2021mlir}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Triton Kernel 编译流程\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces \cite  {pldi/tillet2019triton}}}{11}{figure.caption.10}\protected@file@percent }
\newlabel{figure:triton}{{7}{11}{Triton Kernel 编译流程~\cite {pldi/tillet2019triton}}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}硬件感知的深度学习编译器}{11}{subsection.2.3}\protected@file@percent }
\citation{hpca/mei2023defines}
\citation{hpca/mei2023defines}
\citation{dao2023flashattention}
\citation{dao2023flashattention}
\citation{osdi/shi2023welder}
\citation{osdi/shi2023welder}
\citation{hpca/mei2023defines}
\citation{osdi/zhu2022roller}
\citation{osdi/shi2023welder}
\citation{osdi/wang2024ladder}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}基于分块的内核融合技术}{12}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces 不同融合技术\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces \cite  {hpca/mei2023defines}}}{13}{figure.caption.11}\protected@file@percent }
\newlabel{figure:DeFiNES}{{8}{13}{不同融合技术~\cite {hpca/mei2023defines}}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces FlashAttention-v2 算法流程\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces \cite  {dao2023flashattention}}}{13}{figure.caption.12}\protected@file@percent }
\newlabel{figure:FlashAttention}{{9}{13}{FlashAttention-v2 算法流程~\cite {dao2023flashattention}}{figure.caption.12}{}}
\citation{huang2024orojenesis}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Welder 系统设计\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces \cite  {osdi/shi2023welder}}}{14}{figure.caption.13}\protected@file@percent }
\newlabel{figure:Welder}{{10}{14}{Welder 系统设计~\cite {osdi/shi2023welder}}{figure.caption.13}{}}
\citation{cute}
\citation{CUTLASS}
\citation{arxiv/spector2024thunderkittens}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}基于 Tile 抽象的 GPU 编程 DSL 与编译器}{15}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}CuTe 与 CUTLASS 3.x}{15}{subsubsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}ThunderKittens}{15}{subsubsection.2.5.2}\protected@file@percent }
\citation{arxiv/wang2025tilelang}
\citation{arxiv/ding2025tilus}
\citation{osdi/wang2024ladder}
\citation{gluon}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.3}TileLang}{16}{subsubsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.4}Tilus}{16}{subsubsection.2.5.4}\protected@file@percent }
\citation{osdi/cheng2025pipethreader}
\citation{arxiv/chen2025tawa}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.5}Gluon}{17}{subsubsection.2.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.6}PipeThreader}{17}{subsubsection.2.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.7}Tawa}{17}{subsubsection.2.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.8}小结}{18}{subsubsection.2.5.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}存在的问题}{18}{subsection.2.6}\protected@file@percent }
\citation{nips/vaswani2017attention}
\citation{dao2022flashattention,dao2023flashattention}
\citation{tvm/chen2018tvm}
\citation{xla}
\citation{cgo/baghdadi2019tiramisu}
\citation{pldi/tillet2019triton}
\citation{wolf1991data}
\@writefile{toc}{\contentsline {section}{\numberline {三}基于多内存层级数据流图的硬件感知抽象}{20}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}引言}{20}{subsection.3.1}\protected@file@percent }
\citation{wolf1991data}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}预备知识}{21}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}GPU 内存层级结构}{21}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}仿射变换与数据局部性优化}{21}{subsubsection.3.2.2}\protected@file@percent }
\citation{wolf1991data}
\citation{wolf1991data}
\@writefile{toc}{\contentsline {paragraph}{仿射映射的形式化定义}{22}{paragraph*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{数据复用分析}{22}{paragraph*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{循环变换与分块}{22}{paragraph*.16}\protected@file@percent }
\citation{feautrier1992some}
\citation{bondhugula2008practical}
\@writefile{toc}{\contentsline {paragraph}{迭代域与多面体模型}{23}{paragraph*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{对本课题的启发}{23}{paragraph*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Tensor Core 与矩阵乘累加指令}{24}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}基于数据流的 Affine IR 设计}{24}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces AffineGraph IR 的核心抽象：(a) \textbf  {AffineEdge} 通过基于仿射映射的访问模式连接节点；(b) \textbf  {AffineNode} 为缓冲区、任务和嵌套 AffineGraph 提供统一抽象；(c) \textbf  {AffineGraph} 将节点和边组合成层次化数据流图。}}{25}{figure.caption.19}\protected@file@percent }
\newlabel{figure:affinegraph-abstraction}{{11}{25}{AffineGraph IR 的核心抽象：(a) \textbf {AffineEdge} 通过基于仿射映射的访问模式连接节点；(b) \textbf {AffineNode} 为缓冲区、任务和嵌套 AffineGraph 提供统一抽象；(c) \textbf {AffineGraph} 将节点和边组合成层次化数据流图。}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces AffineGraph IR 中 FlashAttention-2 的数据流表示。该图展示了嵌套的 SuperGraph 节点捕获了块级和线程束级的层次化分块。缓冲区节点明确标注了内存空间：全局内存（蓝色）用于 HBM 中的 Q、K、V、O；共享内存（绿色）用于 SRAM 中的分块数据；寄存器（黄色）用于计算片段。运算符节点（红色）表示 Tensor Core MMA 操作和在线 Softmax。仿射边通过仿射映射变换编码数据移动。融合计算区域展示了 MMA 和 Softmax 操作在没有中间内存写入的情况下执行，数据依赖在最终 MMA 操作之前的合并点处汇聚。}}{26}{figure.caption.20}\protected@file@percent }
\newlabel{figure:affinegraph-flashattention}{{12}{26}{AffineGraph IR 中 FlashAttention-2 的数据流表示。该图展示了嵌套的 SuperGraph 节点捕获了块级和线程束级的层次化分块。缓冲区节点明确标注了内存空间：全局内存（蓝色）用于 HBM 中的 Q、K、V、O；共享内存（绿色）用于 SRAM 中的分块数据；寄存器（黄色）用于计算片段。运算符节点（红色）表示 Tensor Core MMA 操作和在线 Softmax。仿射边通过仿射映射变换编码数据移动。融合计算区域展示了 MMA 和 Softmax 操作在没有中间内存写入的情况下执行，数据依赖在最终 MMA 操作之前的合并点处汇聚。}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}控制流与谓词执行}{28}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}AffineGraph IR 表达力评估}{28}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}代码简洁性分析}{29}{subsubsection.3.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces 不同框架实现相同算法所需的代码行数（LoC）对比。纵轴采用对数坐标。数据来源于各框架公开仓库的真实源码测量。}}{29}{figure.caption.21}\protected@file@percent }
\newlabel{figure:ir_eval_loc}{{13}{29}{不同框架实现相同算法所需的代码行数（LoC）对比。纵轴采用对数坐标。数据来源于各框架公开仓库的真实源码测量。}{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces GEMM 内核实现复杂度的详细对比。括号内标注了各框架的具体源文件。AffineGraph 使用层次化数据流图描述三层内存层级的 GEMM。}}{30}{figure.caption.22}\protected@file@percent }
\newlabel{figure:ir_eval_gemm_detail}{{14}{30}{GEMM 内核实现复杂度的详细对比。括号内标注了各框架的具体源文件。AffineGraph 使用层次化数据流图描述三层内存层级的 GEMM。}{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces FlashAttention-2 实现中不同代码类别的占比分析。AffineGraph IR 中 75\% 的代码用于描述核心计算逻辑，而 CUDA 中仅有 20\%。}}{31}{figure.caption.23}\protected@file@percent }
\newlabel{figure:ir_eval_breakdown}{{15}{31}{FlashAttention-2 实现中不同代码类别的占比分析。AffineGraph IR 中 75\% 的代码用于描述核心计算逻辑，而 CUDA 中仅有 20\%。}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}硬件特性覆盖度}{31}{subsubsection.3.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces 各框架对 9 项关键硬件特性的支持程度矩阵。绿色（{\fontfamily  {pzd}\fontencoding  {U}\fontseries  {m}\fontshape  {n}\selectfont  \char 51}）表示完全自动支持，黄色（$\sim $）表示部分/手动支持，红色（{\fontfamily  {pzd}\fontencoding  {U}\fontseries  {m}\fontshape  {n}\selectfont  \char 55}）表示不支持。AffineGraph IR 是唯一在所有特性上均实现完全自动支持的框架。}}{32}{figure.caption.24}\protected@file@percent }
\newlabel{figure:ir_eval_features}{{16}{32}{各框架对 9 项关键硬件特性的支持程度矩阵。绿色（\cmark ）表示完全自动支持，黄色（$\sim $）表示部分/手动支持，红色（\xmark ）表示不支持。AffineGraph IR 是唯一在所有特性上均实现完全自动支持的框架。}{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}多维能力综合评估}{32}{subsubsection.3.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces 各框架的硬件特性支持总分（满分 18 分）。AffineGraph IR 以 18/18 的满分成为唯一在所有特性上均实现完全自动支持的框架。}}{33}{figure.caption.25}\protected@file@percent }
\newlabel{figure:ir_eval_feature_score}{{17}{33}{各框架的硬件特性支持总分（满分 18 分）。AffineGraph IR 以 18/18 的满分成为唯一在所有特性上均实现完全自动支持的框架。}{figure.caption.25}{}}
\citation{tvm/chen2018tvm}
\citation{dao2022flashattention,dao2023flashattention}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces 五种框架在 7 个维度上的多维能力对比雷达图。AffineGraph IR 在内存抽象、表达力和认知简单性维度上显著优于其他框架。}}{34}{figure.caption.26}\protected@file@percent }
\newlabel{figure:ir_eval_radar}{{18}{34}{五种框架在 7 个维度上的多维能力对比雷达图。AffineGraph IR 在内存抽象、表达力和认知简单性维度上显著优于其他框架。}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {四}基于分块策略的内核融合}{34}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}引言}{34}{subsection.4.1}\protected@file@percent }
\citation{wolf1991data}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}预备知识}{35}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}分块（Tiling）优化}{35}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}软件流水线}{36}{subsubsection.4.2.2}\protected@file@percent }
\citation{williams2009roofline}
\citation{huang2024orojenesis}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Roofline 性能模型与数据移动界限}{37}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}硬件感知优化}{38}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}分块大小与并行度确定}{38}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{符号定义}{38}{paragraph*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{约束模型}{38}{paragraph*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{性能模型}{39}{paragraph*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Warp Layout 的影响}{39}{paragraph*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{模型评估与配置生成}{40}{paragraph*.31}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces GEMM $4096 \times 4096 \times 4096$ 的 Cost Model Tile Size 配置}}{41}{table.caption.32}\protected@file@percent }
\newlabel{table:cost_model_4096}{{1}{41}{GEMM $4096 \times 4096 \times 4096$ 的 Cost Model Tile Size 配置}{table.caption.32}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces GEMM $8192 \times 8192 \times 8192$ 的 Cost Model Tile Size 配置}}{41}{table.caption.33}\protected@file@percent }
\newlabel{table:cost_model_8192}{{2}{41}{GEMM $8192 \times 8192 \times 8192$ 的 Cost Model Tile Size 配置}{table.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces 基于微任务的 GEMM-Reduce 在 NVIDIA Ampere GPU 上的执行模型。该图展示了一个线程束实现原子块的物理执行序列，展示了通过 \texttt  {cp.async} 和 \texttt  {ldmatrix} 指令在内存层次结构（全局内存 $\rightarrow $ 共享内存 $\rightarrow $ 寄存器）之间的数据移动，随后是 Tensor Core MMA 计算和累加。K 循环表示在 K 维度上的迭代归约。}}{42}{figure.caption.34}\protected@file@percent }
\newlabel{figure:micro-task-matmul-reduce}{{19}{42}{基于微任务的 GEMM-Reduce 在 NVIDIA Ampere GPU 上的执行模型。该图展示了一个线程束实现原子块的物理执行序列，展示了通过 \texttt {cp.async} 和 \texttt {ldmatrix} 指令在内存层次结构（全局内存 $\rightarrow $ 共享内存 $\rightarrow $ 寄存器）之间的数据移动，随后是 Tensor Core MMA 计算和累加。K 循环表示在 K 维度上的迭代归约。}{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}层级执行模型}{42}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}高效内存访问优化}{42}{subsection.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces NVIDIA GPU 上的高效内存访问优化策略}}{43}{figure.caption.35}\protected@file@percent }
\newlabel{fig:effective_memory_access}{{20}{43}{NVIDIA GPU 上的高效内存访问优化策略}{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}面向 Hopper 架构的可扩展性}{43}{subsection.4.6}\protected@file@percent }
\newlabel{sec:hopper-extension}{{4.6}{43}{面向 Hopper 架构的可扩展性}{subsection.4.6}{}}
\@writefile{toc}{\contentsline {paragraph}{张量内存加速器（TMA）}{43}{paragraph*.36}\protected@file@percent }
\citation{quack2025}
\@writefile{toc}{\contentsline {paragraph}{线程块集群（Thread Block Clusters）}{44}{paragraph*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Warpgroup 级操作}{44}{paragraph*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Micro-Task 执行模型效率分析}{44}{subsection.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.1}面向内存受限算子的 Micro-Task 分解}{44}{subsubsection.4.7.1}\protected@file@percent }
\citation{liger2024}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Softmax 算子的 Micro-Task 层级化执行序列分解}}{45}{table.caption.39}\protected@file@percent }
\newlabel{table:microtask_membound}{{3}{45}{Softmax 算子的 Micro-Task 层级化执行序列分解}{table.caption.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.2}内存带宽利用率分析}{45}{subsubsection.4.7.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Softmax 内核的内存访问效率分析（H800, $M=16384, N=32768$, FP16）}}{45}{table.caption.40}\protected@file@percent }
\newlabel{table:microtask_bandwidth}{{4}{45}{Softmax 内核的内存访问效率分析（H800, $M=16384, N=32768$, FP16）}{table.caption.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.3}寄存器资源管理与溢出分析}{46}{subsubsection.4.7.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces 不同归约维度下 Softmax 内核的寄存器使用与溢出分析（H800, FP16）}}{46}{table.caption.41}\protected@file@percent }
\newlabel{table:microtask_regspill}{{5}{46}{不同归约维度下 Softmax 内核的寄存器使用与溢出分析（H800, FP16）}{table.caption.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.4}Cluster 归约策略消融实验}{47}{subsubsection.4.7.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces 不同 Cluster Size 对 Softmax 有效带宽的影响（H800, $N=65536$, FP16）}}{47}{table.caption.42}\protected@file@percent }
\newlabel{table:cluster_ablation}{{6}{47}{不同 Cluster Size 对 Softmax 有效带宽的影响（H800, $N=65536$, FP16）}{table.caption.42}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.5}小结}{48}{subsubsection.4.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {五}高效的内核映射策略}{49}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}引言}{49}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}预备知识}{49}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}GPU 执行模型与线程层级}{49}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}异步数据传输与同步机制}{50}{subsubsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}数据布局与 Swizzle 变换}{51}{subsubsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}图降低与代码生成}{51}{subsection.5.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces AffineGraph 代码生成算法}}{52}{algorithm.1}\protected@file@percent }
\newlabel{alg:codegen}{{1}{52}{AffineGraph 代码生成算法}{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces 使用 AffineGraph 的 GEMM 案例研究。 (a) Python DSL 中的 AffineGraph IR，展示了跨越内存层级（全局、共享、寄存器）的缓冲区声明、用于 K 维分块的循环变量，以及定义数据移动模式的仿射映射。 (b) 降低后的数据流图，具有显式的依赖关系，且每条数据传输边都标注了仿射变换矩阵。 (c) 展示矩阵 A 数据流的 GPU 架构映射：全局内存中的 K 循环迭代 CTA 级分块；共享内存中带有 Swizzle$\langle $2,3,3$\rangle $ 的 4-warp (2$\times $2) 协作；寄存器中分解为 4$\times $2 ldmatrix 分块的 WarpTile (64$\times $32)；以及 Tensor Core MMA 执行流水线。 }}{53}{figure.caption.43}\protected@file@percent }
\newlabel{figure:gemm_case}{{21}{53}{使用 AffineGraph 的 GEMM 案例研究。 (a) Python DSL 中的 AffineGraph IR，展示了跨越内存层级（全局、共享、寄存器）的缓冲区声明、用于 K 维分块的循环变量，以及定义数据移动模式的仿射映射。 (b) 降低后的数据流图，具有显式的依赖关系，且每条数据传输边都标注了仿射变换矩阵。 (c) 展示矩阵 A 数据流的 GPU 架构映射：全局内存中的 K 循环迭代 CTA 级分块；共享内存中带有 Swizzle$\langle $2,3,3$\rangle $ 的 4-warp (2$\times $2) 协作；寄存器中分解为 4$\times $2 ldmatrix 分块的 WarpTile (64$\times $32)；以及 Tensor Core MMA 执行流水线。}{figure.caption.43}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}案例研究：以 GEMM 为例}{53}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{层级化 IR 构建与数据流表示}{53}{paragraph*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{布局推断与变换}{54}{paragraph*.47}\protected@file@percent }
\newlabel{lst:gemm_dsl_example}{{1}{55}{使用 AffineGraph IR 实现的 GEMM 示例}{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}{\ignorespaces 使用 AffineGraph IR 实现的 GEMM 示例}}{55}{lstlisting.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{从数据流图生成 CUDA 代码}{55}{paragraph*.48}\protected@file@percent }
\citation{dao2022flashattention}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces AffineGraph 中的布局推断与变换流水线。 (a) 从全局到共享内存的数据加载，根据 WarpLayout 自动进行向量化和合并内存访问。 (b) 共享内存布局推断，展示了如何根据 SharedTile 和 WarpLayout 推导 WarpTile 配置，并采用自适应的 Swizzling 策略来平衡 Bank Conflicts 和 CTA 占用率。 (c) 寄存器级的 BaseTile 抽象，其中单个线程处理8个元素，32个线程协作处理 16x16 的 ld.matrix 块以实现高效的 mma.sync 操作。 }}{56}{figure.caption.46}\protected@file@percent }
\newlabel{figure:layout_inference}{{22}{56}{AffineGraph 中的布局推断与变换流水线。 (a) 从全局到共享内存的数据加载，根据 WarpLayout 自动进行向量化和合并内存访问。 (b) 共享内存布局推断，展示了如何根据 SharedTile 和 WarpLayout 推导 WarpTile 配置，并采用自适应的 Swizzling 策略来平衡 Bank Conflicts 和 CTA 占用率。 (c) 寄存器级的 BaseTile 抽象，其中单个线程处理8个元素，32个线程协作处理 16x16 的 ld.matrix 块以实现高效的 mma.sync 操作。}{figure.caption.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}系统实现}{56}{subsection.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}实验评估}{56}{subsection.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{实验环境设置}{56}{paragraph*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{深度学习负载}{56}{paragraph*.51}\protected@file@percent }
\newlabel{lst:gemm_codegen}{{2}{57}{基于模版库生成的 CUDA kernel}{lstlisting.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}{\ignorespaces 基于模版库生成的 CUDA kernel}}{57}{lstlisting.2}\protected@file@percent }
\citation{huang2024orojenesis}
\citation{CUTLASS}
\citation{pldi/tillet2019triton}
\citation{nips/paszke2019pytorch}
\citation{pldi/tillet2019triton}
\citation{dao2023flashattention}
\@writefile{toc}{\contentsline {paragraph}{性能评估方法论}{58}{paragraph*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{基准对比}{58}{paragraph*.53}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces 不同形状和不同 Warp Layout 下的内存操作（Load/Store）性能对比。柱状图上方的数字表示加速比（CUTLASS/AffineGraph）。AffineGraph 在较大矩阵上取得了最高 1.50 倍的加速。}}{59}{figure.caption.54}\protected@file@percent }
\newlabel{figure:layout_comparison}{{23}{59}{不同形状和不同 Warp Layout 下的内存操作（Load/Store）性能对比。柱状图上方的数字表示加速比（CUTLASS/AffineGraph）。AffineGraph 在较大矩阵上取得了最高 1.50 倍的加速。}{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces AffineGraph 与基准框架的性能对比。 (a) 不同矩阵规模下的标准 GEMM； (b) 不同批量大小下的 Batched GEMM； (c) 融合双 GEMM 操作； (d) 隐藏维度为 128 的 FlashAttention； (e) 隐藏维度为 256 的 FlashAttention； (f) 隐藏维度为 64 的 Block Sparse Attention； (g) 隐藏维度为 128 的 Block Sparse Attention。 纵轴为执行时间（ms），越低越好。}}{59}{figure.caption.55}\protected@file@percent }
\newlabel{figure:affine_evaluation}{{24}{59}{AffineGraph 与基准框架的性能对比。 (a) 不同矩阵规模下的标准 GEMM； (b) 不同批量大小下的 Batched GEMM； (c) 融合双 GEMM 操作； (d) 隐藏维度为 128 的 FlashAttention； (e) 隐藏维度为 256 的 FlashAttention； (f) 隐藏维度为 64 的 Block Sparse Attention； (g) 隐藏维度为 128 的 Block Sparse Attention。 纵轴为执行时间（ms），越低越好。}{figure.caption.55}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.1}NVIDIA A100 上的算子性能}{59}{subsubsection.5.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{内存操作}{60}{paragraph*.56}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GEMM}{60}{paragraph*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{融合双 GEMM}{60}{paragraph*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{FlashAttention}{61}{paragraph*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Block Sparse Attention}{62}{paragraph*.60}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.2}小结}{62}{subsubsection.5.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.6.3}面向 Hopper 架构的可移植性评估}{63}{subsubsection.5.6.3}\protected@file@percent }
\newlabel{sec:hopper-eval}{{5.6.3}{63}{面向 Hopper 架构的可移植性评估}{subsubsection.5.6.3}{}}
\@writefile{toc}{\contentsline {paragraph}{实验设置}{63}{paragraph*.61}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces NVIDIA H800（Hopper）上内存受限操作的性能。 (a) Softmax 延迟。(b) Softmax 有效带宽。 (c) RMSNorm 延迟。(d) RMSNorm 有效带宽。 AffineGraph 在所有配置下均维持约 2900 GB/s 的有效带宽，接近 H800 的 3350 GB/s 峰值 HBM3 带宽。N/A 表示该框架不支持给定的配置。}}{64}{figure.caption.62}\protected@file@percent }
\newlabel{figure:hopper_evaluation}{{25}{64}{NVIDIA H800（Hopper）上内存受限操作的性能。 (a) Softmax 延迟。(b) Softmax 有效带宽。 (c) RMSNorm 延迟。(d) RMSNorm 有效带宽。 AffineGraph 在所有配置下均维持约 2900 GB/s 的有效带宽，接近 H800 的 3350 GB/s 峰值 HBM3 带宽。N/A 表示该框架不支持给定的配置。}{figure.caption.62}{}}
\@writefile{toc}{\contentsline {paragraph}{实验结果}{64}{paragraph*.63}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{分析}{65}{paragraph*.64}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {六}总结和展望}{66}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}总结}{66}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}下一步研究计划}{67}{subsection.6.2}\protected@file@percent }
\citation{*}
\bibdata{bib/ref}
\@writefile{toc}{\contentsline {section}{参考文献}{68}{section*.65}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{致谢}{68}{section*.66}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{作者简历及攻读学位期间发表的学术论文与其他相关学术成果}{69}{section*.68}\protected@file@percent }
\gdef \@abspage@last{73}
